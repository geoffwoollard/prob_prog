{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6663a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66b5cb",
   "metadata": {},
   "source": [
    "## load helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42640bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'V': ['observe3', 'sample2', 'sample1'],\n",
       "  'A': {'sample1': ['sample2'], 'sample2': ['observe3']},\n",
       "  'P': {'sample1': ['sample*', ['normal', 0, 5]],\n",
       "   'sample2': ['sample*', ['uniform-continuous', 0.01, ['abs', 'sample1']]],\n",
       "   'observe3': ['observe*', ['normal', 0, 'sample2'], 7]},\n",
       "  'Y': {'observe3': 7}},\n",
       " 'sample2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import load_helper\n",
    "importlib.reload(load_helper)\n",
    "\n",
    "fname = '5.daphne'\n",
    "graph = load_helper.graph_helper(fname)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b504a",
   "metadata": {},
   "source": [
    "# run from source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e19cdc",
   "metadata": {},
   "source": [
    "## bbvi_algo12\n",
    "* Problem 3\n",
    "  * SGD not working. issues wtih normal support of bounds\n",
    "  * Adam still dips ELBO low for very high batch L (300). issue var zero\n",
    "  * Adam OK, still dips a bit, for T=150, L=30, lr=0.05, getting best ELBO -44 (-23 Masoud)\n",
    "  * not as good: doing T=100, smaller lr=0.01, large L=1000, gets best ELBO -1676 \n",
    "* Problem 4\n",
    "  * T=100, L=20, Adam, lr=0.05, near to peaking, ELBO ~ -480 need to go to ~ -454. run twice as long? another 5-10 min?\n",
    "  * T=250, L=20, Adam lr=0.05, ELBO -466, need to go x3-10 to get peak?, 8 min\n",
    "  \n",
    "* Problem 5\n",
    "  * uniform can't take observes everywhere, so when use uniform-continuoys as proposal, and try to score something outside it's support (it throws an error). it can't score the log_prob, because it is impossible for it to be observed there, so there is zero probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d3a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import primitives\n",
    "importlib.reload(primitives)\n",
    "\n",
    "import evaluation_based_sampling\n",
    "importlib.reload(evaluation_based_sampling)\n",
    "\n",
    "import bbvi\n",
    "importlib.reload(bbvi)\n",
    "\n",
    "from bbvi import graph_bbvi_algo12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695cf0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "T=1000\n",
    "L=20\n",
    "lr=0.05\n",
    "r, logW, sigma = bbvi.graph_bbvi_algo12(graph,T=T,L=L,lr=lr,\n",
    "                                   do_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(logW.mean(1)).plot()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('ELBO')\n",
    "plt.title('{} \\n T={} \\n L={} \\n Adam, lr={}'.format(fname,T,L,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=50\n",
    "L=L\n",
    "lr=lr\n",
    "r, logW, sigma = graph_bbvi_algo12(graph,T=T,L=L,lr=lr,sigma=sigma,do_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afcfac6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5.daphne \\n T=200 \\n L=100 \\n lr=0.05')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(logW.mean(1)).plot()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('ELBO')\n",
    "plt.title('{} \\n T={} \\n L={} \\n lr={}'.format(fname,T,L,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c797915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.205398411750792"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logW.mean(1).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008143a",
   "metadata": {},
   "source": [
    "## problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a9b904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8494)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.distributions.Gamma(tensor(2.),tensor(1.))\n",
    "concentration = tensor(2.)\n",
    "rate = tensor(1./0.5)\n",
    "d=distributions.UniformContinuous(concentration,rate)\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e819360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0, Q after step={'sample2': Gamma(concentration: 2.049999952316284, rate: 1.8545866012573242), 'sample1': Normal(loc: -0.04999999701976776, scale: 4.993239402770996)}\n",
      "t=20, Q after step={'sample2': Gamma(concentration: 2.737981081008911, rate: 1.2945386171340942), 'sample1': Normal(loc: 0.4062788188457489, scale: 5.147683143615723)}\n",
      "t=40, Q after step={'sample2': Gamma(concentration: 2.9851531982421875, rate: 1.0921889543533325), 'sample1': Normal(loc: 0.5101726651191711, scale: 5.190408706665039)}\n",
      "t=60, Q after step={'sample2': Gamma(concentration: 3.0972938537597656, rate: 1.0041407346725464), 'sample1': Normal(loc: 0.40024858713150024, scale: 5.0716023445129395)}\n",
      "t=80, Q after step={'sample2': Gamma(concentration: 3.158691883087158, rate: 0.9651890397071838), 'sample1': Normal(loc: 0.336447536945343, scale: 4.915555477142334)}\n",
      "t=100, Q after step={'sample2': Gamma(concentration: 3.2066032886505127, rate: 0.9367976188659668), 'sample1': Normal(loc: 0.3002406060695648, scale: 4.7262043952941895)}\n",
      "t=120, Q after step={'sample2': Gamma(concentration: 3.2331485748291016, rate: 0.9307222366333008), 'sample1': Normal(loc: 0.24521470069885254, scale: 4.4765520095825195)}\n",
      "t=140, Q after step={'sample2': Gamma(concentration: 3.309584856033325, rate: 0.8948416113853455), 'sample1': Normal(loc: 0.17265008389949799, scale: 4.260249614715576)}\n",
      "t=160, Q after step={'sample2': Gamma(concentration: 3.3723573684692383, rate: 0.8646985292434692), 'sample1': Normal(loc: 0.04060453921556473, scale: 3.9929544925689697)}\n",
      "t=180, Q after step={'sample2': Gamma(concentration: 3.4017558097839355, rate: 0.8635044097900391), 'sample1': Normal(loc: 0.0037052903790026903, scale: 3.7127106189727783)}\n"
     ]
    }
   ],
   "source": [
    "T=200\n",
    "L=100\n",
    "lr=0.05\n",
    "\n",
    "r, logW, sigma = bbvi.graph_bbvi_algo12(graph,T=T,L=L,lr=lr,\n",
    "                                         init_local_env={'prior_dist':{'sample2':distributions.Gamma(concentration,rate)}},\n",
    "                                   #custom_proposals={'sample2':distributions.Gamma(concentration,rate)},\n",
    "                                   do_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ef801",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions.Normal(tensor(0.),tensor(1e-38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc66210",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = evaluation_based_sampling.evaluate(['uniform-continuous',0,1])[0]\n",
    "u = u.make_copy_with_grads()\n",
    "u.log_prob(tensor(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributions import UniformContinuous\n",
    "u = UniformContinuous(tensor(0.),tensor(2.))\n",
    "u.log_prob(tensor(2.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.distributions.Uniform(tensor(0.),tensor(2.))\n",
    "u.log_prob(tensor(2.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8571ee",
   "metadata": {},
   "source": [
    "## $\\lambda_{v,d} \\in \\mathbb{R}^{>1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0003dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributions\n",
    "z3 = torch.ones(3)\n",
    "d = distributions.Categorical(z3)\n",
    "dg = d.make_copy_with_grads()\n",
    "lambda_v = d.Parameters()\n",
    "len(lambda_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbvi import grad_log_prob\n",
    "import bbvi\n",
    "importlib.reload(bbvi)\n",
    "\n",
    "grad_log_prob(dg,tensor(2)).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = distributions.Normal(tensor(0.),tensor(1.))\n",
    "dg = d.make_copy_with_grads()\n",
    "lambda_v = d.Parameters()\n",
    "lambda_v\n",
    "lambda_v[1].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59528176",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_v_d = lambda_v[0]\n",
    "lambda_v_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros_like(lambda_v_d).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4547f683",
   "metadata": {},
   "source": [
    "### elbo_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deaf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "G_v = np.array([[[ 0.94554961, -1.19752276,  0.47344792]],\n",
    " [[ 1.13782573, -1.44912326,  0.1195029 ]]])\n",
    "# assert False, '{}'.format(G_v)\n",
    "G_v.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a062f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "logW = np.ones(2)\n",
    "F_v = G_v*logW.reshape(-1,1,1)\n",
    "\n",
    "n_D_v, D_v, L = G_v.shape\n",
    "assert D_v == 1\n",
    "d=0\n",
    "b_v1 = np.zeros(D_v)\n",
    "cov_sum_d1, var_sum_d1 = 0, 0\n",
    "for j in range(n_D_v):\n",
    "    G_v_1_j = G_v[:,d,j]\n",
    "    F_v_1_j = F_v[:,d,j]\n",
    "    cov_F_G_j = np.cov(F_v[:,d,j],G_v[:,d,j])\n",
    "    cov_sum_d1 += cov_F_G_j[0,1]\n",
    "    var_sum_d1 += cov_F_G_j[1,1]\n",
    "b_v = cov_sum_d1 / var_sum_d1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_hat_v = (F_v - G_v*b_v1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_hat_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2022fc",
   "metadata": {},
   "source": [
    "## distributions.Normal\n",
    "Barens' pseudo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a605fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import primitives\n",
    "importlib.reload(primitives)\n",
    "\n",
    "import evaluation_based_sampling\n",
    "importlib.reload(evaluation_based_sampling)\n",
    "\n",
    "from evaluation_based_sampling import evaluate\n",
    "\n",
    "n = evaluate(['normal',0,1])[0]\n",
    "n.make_copy_with_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributions.normal.Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a529b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributions import Normal\n",
    "\n",
    "n = Normal(tensor(0.),tensor(1.))\n",
    "from primitives import distribution_types\n",
    "n_torch = torch.distributions.normal.Normal(tensor(0.),tensor(1.))\n",
    "isinstance(n_torch,distribution_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6135654",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(n,torch.distributions.normal.Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbvi.eval_algo11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c753d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(bbvi.eval_algo11(['normal',0,1],sigma={})[0],torch.distributions.normal.Normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e685fd",
   "metadata": {},
   "source": [
    "## graph bbvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_based_sampling import topsort\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s')\n",
    "logger_graph = logging.getLogger('simple_example')\n",
    "logger_graph.setLevel(logging.DEBUG)\n",
    "\n",
    "def graph_bbvi(graph,sigma={},do_log=False,verteces_topsorted=None):\n",
    "    \"\"\"This function does ancestral sampling starting from the prior.\n",
    "\n",
    "    graph output from `daphne graph -i sugared.daphne`\n",
    "    * list of length 3\n",
    "      * first entry is defn dict\n",
    "        * {\"string-defn-function-name\":[\"fn\", [\"var_1\", ..., \"var_n\"], e_function_body], ...}\n",
    "      * second entry is graph: {V,A,P,Y}\n",
    "        * \"V\",\"A\",\"P\",\"Y\" are keys in dict\n",
    "        * \"V\" : [\"string_name_vertex_1\", ..., \"string_name_vertex_n\"] # list of string names of vertices\n",
    "        * \"A\" : {\"string_name_vertex_1\" : [..., \"string_name_vertex_i\", ...] # dict of arc pairs (u,v) with u a string key in the dict, and the value a list of string names of the vertices. note that the keys can be things like \"uniform\" and don't have to be vetex name strings\n",
    "        * \"P\" : \"string_name_vertex_i\" : [\"sample*\", e_i] # dict. keys vertex name strings and value a rested list with a linking function in it. typically e_i is a distribution object. \n",
    "        * \"Y\" : observes\n",
    "      * third entry is return\n",
    "        * name of return rv, or constant\n",
    "\n",
    "    \"\"\"\n",
    "    G = graph[1]\n",
    "    verteces = G['V']\n",
    "    arcs = G['A']\n",
    "    if verteces_topsorted is None:\n",
    "        verteces_topsorted = topsort(verteces, arcs)\n",
    "    else:\n",
    "        assert set(verteces) == set(verteces_topsorted)\n",
    "    P = G['P']\n",
    "    Y = G['Y']\n",
    "    sampled_graph = {}\n",
    "    local_env = {}\n",
    "    \n",
    "    # initialize once\n",
    "    d_prior = distributions.Normal(tensor(0.),tensor(1.))\n",
    "    d_prior = d_prior.make_copy_with_grads()\n",
    "    sigma = {'G':{},'logW':tensor(0.),'Q':{'sample2':d_prior}}\n",
    "    \n",
    "    local_env, sigma = evaluate_link_function_bbvi(P,verteces_topsorted,sigma,local_env={},do_log=do_log)\n",
    "\n",
    "    sampled_graph = local_env\n",
    "    return_of_graph = graph[2] # meaning of program, but need to evaluate\n",
    "    # if do_log: print('sample_from_joint local_env',local_env)\n",
    "    # if do_log: print('sample_from_joint sampled_graph',sampled_graph)\n",
    "    E, sigma = eval_algo11(return_of_graph,sigma, local_env = sampled_graph, do_log=do_log)\n",
    "    return E, sampled_graph\n",
    "\n",
    "graph_bbvi(graph,sigma={},do_log=True,verteces_topsorted=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045de0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_based_sampling import evaluate\n",
    "from graph_based_sampling import score\n",
    "from bbvi import grad_log_prob\n",
    "import distributions\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s')\n",
    "logger = logging.getLogger('simple_example')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def evaluate_link_function_bbvi(P,verteces_topsorted,sigma,local_env,do_log):\n",
    "    for vertex in verteces_topsorted:\n",
    "        link_function = P[vertex]\n",
    "        if link_function[0] == 'sample*':\n",
    "            if do_log: logger_graph.info('match case sample*: link_function {}'.format(link_function))\n",
    "            assert len(link_function) == 2\n",
    "            e = link_function[1]\n",
    "            distribution, sigma = evaluate(e,sigma,local_env = local_env, do_log=do_log)\n",
    "            \n",
    "            # bbvi\n",
    "            q = sigma['Q'][vertex]\n",
    "            \n",
    "            constant = q.sample()\n",
    "            G_v = grad_log_prob(q,constant)\n",
    "            sigma['G'][vertex] = G_v\n",
    "            log_wv = score(distribution,constant) - score(q,constant)\n",
    "            sigma['logW'] += log_wv\n",
    "            if do_log: logger.info('match case sample: q {}, constant {}, G_v {}, log_wv {}, logW {}'.format(q, constant, G_v,log_wv, sigma['logW']))\n",
    "            #return constant, sigma # match shape in number base case\n",
    "            update_local_env = {vertex:constant}\n",
    "            local_env.update(update_local_env)\n",
    "        \n",
    "                    \n",
    "#             if do_log: logger_graph.info('match case sample*: distribution {}, sigma {}'.format(sigma, distribution))\n",
    "#             E = distribution.sample() # now have concrete value. need to pass it as var to evaluate\n",
    "#             update_local_env = {vertex:E}#{vertex:E, vertex+'_dist':distribution}\n",
    "#             local_env.update(update_local_env)\n",
    "#             local_env['prior_dist'][vertex] = distribution\n",
    "        elif link_function[0] == 'observe*':\n",
    "            if do_log: logger_graph.info('match case observe*: link_function {} sigma {}'.format(link_function, sigma))\n",
    "            e1, e2 = link_function[1:]\n",
    "            d1, sigma = evaluate(e1,sigma,local_env,do_log=do_log)\n",
    "            c2, sigma = evaluate(e2,sigma,local_env,do_log=do_log)\n",
    "            log_w = score(d1,c2)\n",
    "            sigma  += log_w\n",
    "            if do_log: logger_graph.info('match case observe*: d1 {}, c2 {}, log_w {}, sigma {}'.format(d1, c2, log_w, sigma))\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    return local_env, sigma\n",
    "\n",
    "d_prior = distributions.Normal(tensor(0.),tensor(1.))\n",
    "d_prior = d_prior.make_copy_with_grads()\n",
    "evaluate_link_function_bbvi(P={'sample2': ['sample*', ['normal', 1, ['sqrt', 5]]]},\n",
    "                            verteces_topsorted = ['sample2'],\n",
    "                            sigma={'G':{},'logW':tensor(0.),'Q':{'sample2':d_prior}},\n",
    "                            local_env={},\n",
    "                            do_log=False\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_based_sampling import topsort\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s')\n",
    "logger_graph = logging.getLogger('simple_example')\n",
    "logger_graph.setLevel(logging.DEBUG)\n",
    "\n",
    "from graph_based_sampling import sample_from_joint\n",
    "\n",
    "def graph_bbvi_algo12(graph,sigma={},do_log=False,verteces_topsorted=None):\n",
    "    \"\"\"This function does ancestral sampling starting from the prior.\n",
    "    \n",
    "    And then ancestral sampling from a learned proposal with bbvi\n",
    "\n",
    "    graph output from `daphne graph -i sugared.daphne`\n",
    "    * list of length 3\n",
    "      * first entry is defn dict\n",
    "        * {\"string-defn-function-name\":[\"fn\", [\"var_1\", ..., \"var_n\"], e_function_body], ...}\n",
    "      * second entry is graph: {V,A,P,Y}\n",
    "        * \"V\",\"A\",\"P\",\"Y\" are keys in dict\n",
    "        * \"V\" : [\"string_name_vertex_1\", ..., \"string_name_vertex_n\"] # list of string names of vertices\n",
    "        * \"A\" : {\"string_name_vertex_1\" : [..., \"string_name_vertex_i\", ...] # dict of arc pairs (u,v) with u a string key in the dict, and the value a list of string names of the vertices. note that the keys can be things like \"uniform\" and don't have to be vetex name strings\n",
    "        * \"P\" : \"string_name_vertex_i\" : [\"sample*\", e_i] # dict. keys vertex name strings and value a rested list with a linking function in it. typically e_i is a distribution object. \n",
    "        * \"Y\" : observes\n",
    "      * third entry is return\n",
    "        * name of return rv, or constant\n",
    "\n",
    "    \"\"\"\n",
    "    G = graph[1]\n",
    "    verteces = G['V']\n",
    "    arcs = G['A']\n",
    "    if verteces_topsorted is None:\n",
    "        verteces_topsorted = topsort(verteces, arcs)\n",
    "    else:\n",
    "        assert set(verteces) == set(verteces_topsorted)\n",
    "    P = G['P']\n",
    "    Y = G['Y']\n",
    "    \n",
    "    E, sampled_graph = sample_from_joint(graph,do_log=do_log)\n",
    "    print('sampled_graph',sampled_graph)\n",
    "    \n",
    "    local_env = {}\n",
    "    \n",
    "    # initialize once\n",
    "    d_prior = distributions.Normal(tensor(0.),tensor(1.))\n",
    "    d_prior = d_prior.make_copy_with_grads()\n",
    "    sigma = {'G':{},'logW':tensor(0.),'Q':{}}\n",
    "    for vertex in sampled_graph['prior_dist'].keys():\n",
    "        d_prior = sampled_graph['prior_dist'][vertex]\n",
    "        d_prior_withgrads = d_prior.make_copy_with_grads()\n",
    "        sigma['Q'][vertex] = d_prior_withgrads\n",
    "    print('sigma',sigma)\n",
    "    \n",
    "    local_env, sigma = evaluate_link_function_algo11(P,verteces_topsorted,sigma,local_env={},do_log=do_log)\n",
    "\n",
    "    sampled_graph = local_env\n",
    "    return_of_graph = graph[2] # meaning of program, but need to evaluate\n",
    "    # if do_log: print('sample_from_joint local_env',local_env)\n",
    "    # if do_log: print('sample_from_joint sampled_graph',sampled_graph)\n",
    "    E, sigma = eval_algo11_deterministic(return_of_graph,sigma, local_env = sampled_graph, do_log=do_log)\n",
    "    return E, sampled_graph, sigma\n",
    "\n",
    "graph_bbvi_algo12(graph,sigma={},do_log=False,verteces_topsorted=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58eae6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6062bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_based_sampling import evaluate\n",
    "from graph_based_sampling import score\n",
    "from bbvi import grad_log_prob\n",
    "import distributions\n",
    "\n",
    "import bbvi\n",
    "importlib.reload(bbvi)\n",
    "from bbvi import eval_algo11_deterministic\n",
    "\n",
    "def evaluate_link_function_algo11(P,verteces_topsorted,sigma,local_env,do_log):\n",
    "    for vertex in verteces_topsorted:\n",
    "        link_function = P[vertex]\n",
    "        if link_function[0] == 'sample*':\n",
    "            if do_log: logger_graph.info('match case sample*: link_function {}'.format(link_function))\n",
    "            assert len(link_function) == 2\n",
    "            e = link_function[1]\n",
    "            # because e evaluates to distribution in linking function\n",
    "            # no sample or observe in eval_algo11\n",
    "            distribution, sigma = eval_algo11_deterministic(e,sigma,local_env = local_env, do_log=do_log) \n",
    "            \n",
    "            # bbvi\n",
    "            q = sigma['Q'][vertex]\n",
    "            \n",
    "            constant = q.sample()\n",
    "            G_v = grad_log_prob(q,constant)\n",
    "            sigma['G'][vertex] = G_v\n",
    "            log_wv = score(distribution,constant) - score(q,constant)\n",
    "            sigma['logW'] += log_wv\n",
    "            if do_log: logger.info('match case sample: q {}, constant {}, G_v {}, log_wv {}, logW {}'.format(q, constant, G_v,log_wv, sigma['logW']))\n",
    "#             #return constant, sigma # match shape in number base case\n",
    "            update_local_env = {vertex:constant}\n",
    "            local_env.update(update_local_env)\n",
    "        \n",
    "                    \n",
    "#             if do_log: logger_graph.info('match case sample*: distribution {}, sigma {}'.format(sigma, distribution))\n",
    "#             E = distribution.sample() # now have concrete value. need to pass it as var to evaluate\n",
    "#             update_local_env = {vertex:E}#{vertex:E, vertex+'_dist':distribution}\n",
    "#             local_env.update(update_local_env)\n",
    "#             local_env['prior_dist'][vertex] = distribution\n",
    "        elif link_function[0] == 'observe*':\n",
    "            \n",
    "            if do_log: logger_graph.info('match case observe*: link_function {} sigma {}'.format(link_function, sigma))\n",
    "            e1, e2 = link_function[1:]\n",
    "            d1, sigma = eval_algo11_deterministic(e1,sigma,local_env,do_log=do_log)\n",
    "            c2, sigma = eval_algo11_deterministic(e2,sigma,local_env,do_log=do_log)\n",
    "            log_w = score(d1,c2)\n",
    "            sigma['logW'] += log_w\n",
    "            if do_log: logger_graph.info('match case observe*: d1 {}, c2 {}, log_w {}, sigma {}'.format(d1, c2, log_w, sigma))\n",
    "    \n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    return local_env, sigma\n",
    "\n",
    "d_prior = distributions.Normal(tensor(0.),tensor(2.))\n",
    "d_prior = d_prior.make_copy_with_grads()\n",
    "evaluate_link_function_algo11(P={'sample2': ['sample*', ['normal', 1, ['sqrt', 1]]]},\n",
    "                            verteces_topsorted = ['sample2'],\n",
    "                            sigma={'G':{},'logW':tensor(0.),'Q':{'sample2':d_prior}},\n",
    "                            local_env={},\n",
    "                            do_log=False\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15ae37",
   "metadata": {},
   "source": [
    "## elbo_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bbvi\n",
    "importlib.reload(bbvi)\n",
    "\n",
    "from bbvi import elbo_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5d76f",
   "metadata": {},
   "source": [
    "## grad_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d35b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bbvi\n",
    "importlib.reload(bbvi)\n",
    "\n",
    "from bbvi import grad_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = tensor(0.)\n",
    "scale = tensor(1.)\n",
    "q_nograd = Normal(loc,scale)\n",
    "q = q_nograd.make_copy_with_grads()\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f97ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tensor(11.)\n",
    "\n",
    "bbvi.grad_log_prob(q,c) # we need to move in the -ve direction of the gradient to make log_prob come down and maximize our log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc03126",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_v = q.Parameters()\n",
    "lambda_v[0].grad, lambda_v[1].grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=0.001)\n",
    "optimizer(lambda_v)\n",
    "optimizer.step()\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387232c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a311de",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_v[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_v[0].zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de530457",
   "metadata": {},
   "source": [
    "## distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e006c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributions.normal.Normal(loc,scale).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a54e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = tensor(0.)\n",
    "scale = tensor(10.)\n",
    "d = Normal(loc,scale)\n",
    "\n",
    "dg = d.make_copy_with_grads()\n",
    "\n",
    "dg.Parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(dg.Parameters(), lr=0.003)\n",
    "\n",
    "data = torch.tensor([2.,2.001,2.01,1.99,2,2,2,2,2,2,2,2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    nlp = -(dg.log_prob(data)).sum() # observe 2 from distribution\n",
    "    nlp.backward()\n",
    "    optimizer.step() # this is what changes dg.Parameters() \n",
    "    optimizer.zero_grad() # so doesn't accumulate\n",
    "    print(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397aaf83",
   "metadata": {},
   "source": [
    "## evaluator algo 11\n",
    "* This evaluator is algorithm 11 in the textbook, p. 130\n",
    "* for case `sample v e`\n",
    "  * it evaluates $e, \\sigma, l \\rightarrow d, \\sigma$ recursively\n",
    "  * if v is outside the domain of the proposal\n",
    "    * initialize the proposal using the prior\n",
    "    * store this distribution in `sigma[Q[v]]`\n",
    "  * sample from the proposal, to get `c`\n",
    "  * get the `grad-log-prob` of the proposal evaluated at `c`\n",
    "    * store this in `sigma[G[v]]`\n",
    "  * score `c` w.r.t. the distributions `d` and `sigma[Q[v]]`\n",
    "    * accumulate in `sigma[logW]`\n",
    "  * return `c,sigma`\n",
    "* for case `observe v e1 e2`\n",
    "  * eval $e1 \\rightarrow d$ and $e2 \\rightarrow c$\n",
    "  * score `c` w.r.t. `d` and accumulate in `sigma[logW]`\n",
    "  * return `c, sigma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import evaluation_based_sampling\n",
    "importlib.reload(evaluation_based_sampling)\n",
    "from evaluation_based_sampling import eval_algo11\n",
    "\n",
    "import graph_based_sampling\n",
    "importlib.reload(graph_based_sampling)\n",
    "from graph_based_sampling import sample_from_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "E, sampled_graph = sample_from_joint(graph,do_log=False)\n",
    "sampled_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, sigma = eval_algo11(['sample',['normal',0,1]],sigma={'logW':tensor(0.),'Q':{},'grad':{}},local_env = sampled_graph, vertex='sample2')\n",
    "r, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_algo11(['observe',['normal',0,1],-1],sigma={'logW':tensor(0.),'Q':{},'grad':{}},vertex='sample2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import distributions\n",
    "# qq = distributions.Normal(loc,scale)\n",
    "# qq.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d65441",
   "metadata": {},
   "source": [
    "## grad-log-prob\n",
    "* line 9 of algo 11, p. 130\n",
    "* there is no optimization happening in the evaluator, this happens in algo 12, p. 131, line 26\n",
    "* we just need the gradient of the log prob of `Q[v]` (ie Q wrt v) evaluated at `c` to be stored in `sigma[G[v]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3338f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributions import Normal\n",
    "sigma = {}\n",
    "sigma['G'] = {}\n",
    "vertex='sample2'\n",
    "\n",
    "loc = tensor(0.)\n",
    "scale = tensor(1.)\n",
    "q_nograd = Normal(loc,scale)\n",
    "q = q_nograd.make_copy_with_grads()\n",
    "c = tensor(1.)#q.sample()\n",
    "\n",
    "def grad_log_prob(distribution_unconst_optim,c):\n",
    "    log_prob = distribution_unconst_optim.log_prob(c)\n",
    "    log_prob.backward()\n",
    "    lambda_v = distribution_unconst_optim.Parameters()\n",
    "    D_v = len(lambda_v)\n",
    "    G_v = torch.zeros(D_v)\n",
    "    for d in range(D_v):\n",
    "        lambda_v_d = lambda_v[d]\n",
    "        G_v[d] = lambda_v_d.grad\n",
    "    return G_v\n",
    "\n",
    "G_v = grad_log_prob(q,c)\n",
    "sigma['G'][vertex] = G_v\n",
    "c, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9121d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_prob = dg.log_prob(tensor(0.))\n",
    "# log_prob\n",
    "# log_prob.backward()\n",
    "# G_v = dg\n",
    "# dg.Parameters()[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d26a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5ee7c",
   "metadata": {},
   "source": [
    "## optimizer step\n",
    "* loop through vertices\n",
    "* get current params in Q(v)\n",
    "* do optimization (step)\n",
    "* set params in Q(v) using new steps\n",
    "\n",
    "* input\n",
    "  * distribution Q(v)\n",
    "  * gradient estimation g_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d987fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600da2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bc73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_hat['sample2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work\n",
    "\n",
    "# epsilon = 0.01\n",
    "# lambda_v_p = torch.zeros(2)\n",
    "# lambda_v = sigma['Q']['sample2'].Parameters()\n",
    "# for idx in range(2):\n",
    "#     lambda_v_p[idx] = lambda_v[idx] - epsilon*g_hat['sample2'][idx]\n",
    "#     sigma['Q']['sample2'].Parameters()[idx] = lambda_v_p[idx]\n",
    "# sigma['Q']['sample2'].Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa0f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_step(Q,g_hat):\n",
    "    \"\"\"\n",
    "    no return of Q since modifies in place, and can't deep copy Q, and copy Q still accumulates\n",
    "    \"\"\"\n",
    "    for v in g_hat.keys():\n",
    "        lambda_v = Q[v].Parameters()\n",
    "        optimizer = torch.optim.Adam(lambda_v, lr=1e-2)\n",
    "        D_v = len(lambda_v)\n",
    "\n",
    "        for idx in range(D_v):\n",
    "            param = lambda_v[idx]\n",
    "        #     param.requires_grad = True # TODO: include???\n",
    "\n",
    "            param.grad = tensor(g_hat['sample2'][idx],dtype=torch.float32)\n",
    "        optimizer.step() # moves lambda_v\n",
    "        optimizer.zero_grad() # TODO: need this?      \n",
    "    \n",
    "\n",
    "Q = sigma['Q']\n",
    "optimizer_step(Q,g_hat)\n",
    "Q\n",
    "    #param.grad = tensor(g_hat['sample2'][0])\n",
    "    # param.grad = torch.from_numpy(g_hat['sample2'][0:1])\n",
    "    #param.grad = torch.from_numpy(np.zeros(param.grad.shape)).type(param.grad.dtype).to(param.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df172983",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68c7e9",
   "metadata": {},
   "source": [
    "## elbo-gradients\n",
    "* input \n",
    "  * gradients for samples 1:L. \n",
    "    * These are put in sigma by the evaluator\n",
    "    * try having a dictionary that maps a sample vertex string (e.g. \"sample2\") to a list of torch objects\n",
    "  * logWs for samples 1:L. These are put in sigma by the evaluator\n",
    "    * try having a dictionary that maps a sample vertex steing (e.g. \"sample2\") to a 0D torch array\n",
    "* the body of this function, for each variable v\n",
    "  * computes the cov(F,G) and var(G) over the samples, and computes b_hat\n",
    "  * computes the estimate of the gradient, g_hat, with the samples summed over\n",
    "* returns\n",
    "  * g_hat\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed60d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph[1]\n",
    "P = G['P']\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa982b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma={}\n",
    "# sigma['grad'] = {}\n",
    "# sigma['logW'] = tensor(0.)\n",
    "# sigma['grad']['sample2'] = q.Parameters()\n",
    "\n",
    "# sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, sigma = eval_algo11(['sample',['normal',1,1.1]],sigma={'logW':tensor(0.),'Q':{},'grad':{}},vertex='sample2')\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def elbo_gradients(G,logW,union_G_keys):\n",
    "#     for v in union_G_keys:\n",
    "#         #F_v = []\n",
    "#         G_v = []\n",
    "#         g_hat = {}\n",
    "#         for l in range(L):\n",
    "#             G_l = G[l]\n",
    "#             if v in G_l.keys():\n",
    "#                 G_l_v = G_l[v].tolist()\n",
    "#                 G_v.append(G_l_v)\n",
    "#                 D_v = len(G_l_v)\n",
    "#                 #F_v_l = G_l_v*logW[t][l]\n",
    "#                 #F_v.append(F_v_l) # data specific tolist might not always work\n",
    "#             else:\n",
    "#                 assert False, 'zero not implemented'\n",
    "#         G_v = np.array(G_v)\n",
    "#         F_v = G_v*logW.reshape(-1,1)\n",
    "\n",
    "#         # cov and var to compute b_v\n",
    "#         assert G_v.ndim == 2\n",
    "#         D_v = G_v.shape[1]\n",
    "#         b_v = np.zeros(D_v)\n",
    "#         for d in range(D_v):\n",
    "#             F_v_d = F_v[:,d]\n",
    "#             G_v_d = G_v[:,d]\n",
    "#             cov_F_G = np.cov(F_v_d,G_v_d)\n",
    "#             b_v[d] = cov_F_G[0,1]/cov_F_G[1,1]\n",
    "#         g_hat_v = (F_v - G_v*b_v).sum(0)  # sum over samples\n",
    "#         g_hat[v] = g_hat_v\n",
    "#     return g_hat\n",
    "    \n",
    "# elbo_gradients(G,logW[t],union_G_keys=set(['sample2']))  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbo_gradients(G,logW,union_G_keys):\n",
    "    for v in union_G_keys:\n",
    "        #F_v = []\n",
    "        G_v = []\n",
    "        g_hat = {}\n",
    "        for l in range(L):\n",
    "            G_l = G[l]\n",
    "            if v in G_l.keys():\n",
    "                G_l_v = G_l[v].tolist()\n",
    "                G_v.append(G_l_v)\n",
    "                D_v = len(G_l_v)\n",
    "                #F_v_l = G_l_v*logW[t][l]\n",
    "                #F_v.append(F_v_l) # data specific tolist might not always work\n",
    "            else:\n",
    "                assert False, 'zero not implemented'\n",
    "        G_v = np.array(G_v)\n",
    "        F_v = G_v*logW.reshape(-1,1)\n",
    "\n",
    "        # cov and var to compute b_v\n",
    "        assert G_v.ndim == 2\n",
    "        D_v = G_v.shape[1]\n",
    "        b_v = np.zeros(D_v)\n",
    "        for d in range(D_v):\n",
    "            F_v_d = F_v[:,d]\n",
    "            G_v_d = G_v[:,d]\n",
    "            cov_F_G = np.cov(F_v_d,G_v_d)\n",
    "            b_v[d] = cov_F_G[0,1]/cov_F_G[1,1]\n",
    "        g_hat_v = (F_v - G_v*b_v).mean(0)  # sum over samples divided by L\n",
    "        g_hat[v] = g_hat_v\n",
    "    return g_hat\n",
    "    \n",
    "elbo_gradients(G,logW[t],union_G_keys=set(['sample2']))  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G[0]['sample2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499df4e5",
   "metadata": {},
   "source": [
    "## BBVI\n",
    "* input \n",
    "  * T : int time steps\n",
    "  * L : int num_samples\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import evaluation_based_sampling\n",
    "importlib.reload(evaluation_based_sampling)\n",
    "\n",
    "from evaluation_based_sampling import eval_algo11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bbvi_algo12(T,L):\n",
    "    r, G = [], []\n",
    "    logW = np.zeros((T,L))\n",
    "\n",
    "    E, sampled_graph = sample_from_joint(graph,do_log=False)\n",
    "\n",
    "    sigma={'logW':tensor(0.),'Q':{},'grad':{}}\n",
    "    e = ['sample',['normal',1,1.1]]\n",
    "\n",
    "    for t in range(T):\n",
    "        G = []\n",
    "        r_t=[]\n",
    "        union_G_t_keys = set()\n",
    "        for l in range(L):\n",
    "            # loop through vertex and evaluate linker functions as e\n",
    "            r_t_l, sigma = eval_algo11(e,sigma=sigma,local_env = sampled_graph, vertex='sample2',do_log=False)\n",
    "            logW[t,l] = sigma['logW'].item()\n",
    "            G_l = (sigma['grad']).copy()\n",
    "            union_G_keys.update(set(G_l.keys()))\n",
    "            G.append(G_l)\n",
    "            r_t.append(r_t_l)\n",
    "        g_hat = elbo_gradients(G,logW[t],union_G_keys) \n",
    "        Q = sigma['Q']\n",
    "        optimizer_step(Q,g_hat) # in place modification of Q\n",
    "\n",
    "        r.append(r_t)\n",
    "    return r, logW\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=3\n",
    "L=50\n",
    "bbvi_algo12(T,L)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma={'logW':tensor(0.),'Q':{},'grad':{}}\n",
    "r, sigma = eval_algo11(e,sigma=sigma,local_env = sampled_graph, vertex='sample2',do_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20202ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r, sigma = eval_algo11(['sample',['normal',0,1]],sigma={'logW':tensor(0.),'Q':{},'grad':{}},local_env = sampled_graph, vertex='sample2')\n",
    "# r, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex='sample2'\n",
    "q = sigma['Q'][vertex]\n",
    "\n",
    "grad_log_prob(q,tensor(0.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
