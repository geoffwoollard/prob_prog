{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8313b6e9",
   "metadata": {},
   "source": [
    "# HW5\n",
    "Geoffrey Woollard\n",
    "\n",
    "My code lives in the repo https://github.com/geoffwoollard/prob_prog\n",
    "\n",
    "# Acknowledgments\n",
    "For this assignment I primarily acknowledge the patient discussions with Jordan Lovrod, where she held my hand and walked me through the resursive structure of declaring lambda `fn`s, and the disrinctions between a return from calling something from the `Procedure` class and a `Procedure` object itself. She also supplied code for the classes `Env`, and `Procedure`.  \n",
    "* Ilias Karimalis on the address structure and how it dynamically tracks the evaluations of the dynamic computational graph\n",
    "* Alan Milligan, Gaurav Bhatt, Masoud Mokhtari and everyone else on Slack for what to do when hitting snags, especially on `empty?`, and `hash-map`, `put` and `get` for handling `str` keys.\n",
    "* Kim Dinh's comments on the interpretation of problem 1 as a Geometric distribution\n",
    "* the baseline results provided by Lironne Kurzman\n",
    "* hw6 starter code for some parts of the `eval_hoppl`, especially the double quotes, and some `primitives`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b929e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOPPL test 1 passed\n",
      "FOPPL test 2 passed\n",
      "FOPPL test 3 passed\n",
      "FOPPL test 4 passed\n",
      "FOPPL test 5 passed\n",
      "FOPPL test 6 passed\n",
      "FOPPL test 7 passed\n",
      "FOPPL test 8 passed\n",
      "FOPPL test 9 passed\n",
      "FOPPL test 10 passed\n",
      "FOPPL test 11 passed\n",
      "FOPPL test 12 passed\n",
      "FOPPL test 13 passed\n",
      "HOPPL test 1 passed\n",
      "HOPPL test 2 passed\n",
      "HOPPL test 3 passed\n",
      "HOPPL test 4 passed\n",
      "HOPPL test 5 passed\n",
      "HOPPL test 6 passed\n",
      "HOPPL test 7 passed\n",
      "HOPPL test 8 passed\n",
      "HOPPL test 9 passed\n",
      "HOPPL test 10 passed\n",
      "HOPPL test 11 passed\n",
      "HOPPL test 12 passed\n",
      "All deterministic tests passed\n",
      "('normal', 5, 1.4142136)\n",
      "p value 0.9521132603290829\n",
      "('beta', 2.0, 5.0)\n",
      "p value 0.8268444534006023\n",
      "('exponential', 0.0, 5.0)\n",
      "p value 0.3859297323773355\n",
      "('normal', 5.3, 3.2)\n",
      "p value 0.6247795543285082\n",
      "('normalmix', 0.1, -1, 0.3, 0.9, 1, 0.3)\n",
      "p value 0.8588495916821821\n",
      "('normal', 0, 1.44)\n",
      "p value 0.6629150112938403\n",
      "All probabilistic tests passed\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 1:\n",
      "tensor(56)\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 2:\n",
      "tensor(-1.5379)\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 3:\n",
      "tensor([1, 2, 1, 0, 0, 2, 1, 1, 1, 0, 0, 0, 2, 0, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python evaluator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca6ef8",
   "metadata": {},
   "source": [
    "# Code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b978bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dill.source import getsource, getsourcelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b230d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 def evaluate(exp, env=None,do_log=False): #TODO: add sigma, or something\n",
      "1 \n",
      "2     if env is None:\n",
      "3         env = standard_env()\n",
      "4 \n",
      "5     fn, _ = eval_hoppl(exp,env,sigma=None, do_log=do_log)\n",
      "6     ret, sigma = fn(\"\")\n",
      "7     if do_log: print('return',ret)\n",
      "8     return ret\n",
      "\n",
      "0 class Env():\n",
      "1     \"An environment: a dict of {'var': val} pairs, with an outer Env.\"\n",
      "2     def __init__(self, parms=(), args=(), outer=None):\n",
      "3         self.data = pmap(zip(parms, args))\n",
      "4         self.outer = outer\n",
      "5         if outer is None:\n",
      "6             self.level = 0\n",
      "7         else:\n",
      "8             self.level = outer.level+1\n",
      "9     def __getitem__(self, item):\n",
      "10         return self.data[item]\n",
      "11     def find(self, var):\n",
      "12         \"Find the innermost Env where var appears.\"\n",
      "13         if (var in self.data):\n",
      "14             return self\n",
      "15         else:\n",
      "16             if self.outer is not None:\n",
      "17                 return self.outer.find(var)\n",
      "18             else:\n",
      "19                 raise RuntimeError('var \"{}\" not found in outermost scope'.format(var))\n",
      "20     \n",
      "21     def print_env(self, print_lowest=False):\n",
      "22         print_limit = 1 if print_lowest == False else 0\n",
      "23         outer = self\n",
      "24         while outer is not None:\n",
      "25             if outer.level >= print_limit:\n",
      "26                 print('Scope on level ', outer.level)\n",
      "27                 if 'f' in outer:\n",
      "28                     print('Found f, ')\n",
      "29                     print(outer['f'].body)\n",
      "30                     print(outer['f'].parms)\n",
      "31                     print(outer['f'].env)\n",
      "32                 print(outer,'\\n')\n",
      "33             outer = outer.outer\n",
      "\n",
      "0 class Procedure(object):\n",
      "1     \"A user-defined Scheme procedure.\"\n",
      "2     def __init__(self, parms, body, env,do_log):\n",
      "3         self.parms, self.body, self.env = parms, body, env\n",
      "4         self.do_log = do_log\n",
      "5     def __call__(self, *args): \n",
      "6         new_env = copy.deepcopy(self.env)\n",
      "7         return eval_hoppl(self.body, Env(self.parms, args, new_env),do_log=self.do_log)\n",
      "\n",
      "0 def standard_env():\n",
      "1     \"An environment with some Scheme standard procedures.\"\n",
      "2     env = Env(penv.keys(), penv.values())\n",
      "3     return env\n",
      "\n",
      "0 def eval_hoppl(x,env=standard_env(),sigma=None,do_log=False):\n",
      "1     # TODO: remove default env=standard_env()\n",
      "2 \n",
      "3     if do_log: print('x',x)\n",
      "4     \n",
      "5     if isinstance(x, list):\n",
      "6         op, param, *args = x\n",
      "7 \n",
      "8         if op == 'if':\n",
      "9             assert len(x) == 4\n",
      "10             test, conseq, alt = x[1:4]\n",
      "11             if do_log: print('case if: x',x)\n",
      "12             exp = (conseq if eval_hoppl(test, env, sigma,do_log=do_log)[0] else alt) # be careful to get return in [0] and not sigma!!!\n",
      "13             if do_log: print('case if: exp',exp)\n",
      "14             return eval_hoppl(exp, env, sigma,do_log=do_log)\n",
      "15 \n",
      "16         if op == 'sample':\n",
      "17             if do_log: print('case sample: x',x)\n",
      "18             _, address, exp_distribution = x\n",
      "19             distribution, sigma = eval_hoppl(exp_distribution, env, sigma,do_log=do_log)\n",
      "20             if do_log: print('case sample: distribution',distribution)\n",
      "21             evaluated_sample = distribution.sample()\n",
      "22             if do_log: print('case sample: evaluated_sample',evaluated_sample)\n",
      "23             return evaluated_sample, sigma\n",
      "24 \n",
      "25         elif op == 'observe':\n",
      "26             if do_log: print('case observe: (pass)')\n",
      "27             return 'observed', sigma\n",
      "28         elif op == 'push-address':\n",
      "29             return '', sigma\n",
      "30         elif op == 'fn':\n",
      "31             if do_log: print('case fn: args',args)\n",
      "32             body = args[0]\n",
      "33             return Procedure(param, body, env, do_log=do_log), sigma # has eval in it\n",
      "34             # param ['alpha', 'x']\n",
      "35             # body ['*', ['push-address', 'alpha', 'addr2'], 'x', 'x']\n",
      "36             # env\n",
      "37         \n",
      "38         else:\n",
      "39             if do_log: print('case else: x',x)\n",
      "40             proc, _ = eval_hoppl(op, env, sigma,do_log=do_log)\n",
      "41             vals = ['']\n",
      "42             if do_log: print('case else: args',args)\n",
      "43             vals.extend([eval_hoppl(arg, env, sigma,do_log=do_log)[0] for arg in args])\n",
      "44             if do_log: print('case else: vals',vals)\n",
      "45             if do_log: print('case Procedure:', proc, vals)\n",
      "46 \n",
      "47             if isinstance(proc, Procedure): # lambdas, not primitives\n",
      "48                 r, _ = proc(*vals)\n",
      "49                 if do_log: print('case Procedure: r', r)\n",
      "50             else:\n",
      "51                 if do_log: print('case primitives: vals[1:]', vals[1:])\n",
      "52                 r = proc(vals[1:]) # primitives\n",
      "53                 if do_log: print('case primitives: r', r)\n",
      "54                 \n",
      "55             return r, sigma\n",
      "56 \n",
      "57     # base cases\n",
      "58     elif isinstance(x,str):\n",
      "59         if x[0] == \"\\\"\":  # daphne output: strings have double, double quotes\n",
      "60             return x[1:-1], sigma\n",
      "61 \n",
      "62         lowest_env = env.find(x)\n",
      "63         return lowest_env[x], sigma\n",
      "64 \n",
      "65     elif isinstance(x,(float,int,bool)):\n",
      "66         return torch.tensor(x), sigma\n",
      "67 \n",
      "68     else:\n",
      "69         raise ValueError('unkown expression case')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluator import evaluate, Env, Procedure, standard_env, eval_hoppl\n",
    "\n",
    "list_of_programs = [evaluate, Env, Procedure, standard_env, eval_hoppl]\n",
    "\n",
    "for program in list_of_programs:\n",
    "    for line_number, function_line in enumerate(getsourcelines(program)[0]):\n",
    "        print(line_number, function_line,end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92acb37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \"\"\"primitives (and distributions) used to evaluate algorithm 6 in \n",
      "1 van de Meent, J.-W., Paige, B., Yang, H., & Wood, F. (2018). \n",
      "2 An Introduction to Probabilistic Programming, XX(Xx), 1â€“221. \n",
      "3 http://doi.org/10.1561/XXXXXXXXXX\n",
      "4 \n",
      "5 Acknowledgements to Yuan T https://github.com/yuant95/CPSC532W/blob/master/CS532-HW2/primitives.py\n",
      "6 and \n",
      "7 Masoud Mokhtari https://github.com/MasoudMo/CPSC-532W/blob/master/HW2/primitives.py\n",
      "8 and\n",
      "9 HW6 starter code https://www.cs.ubc.ca/~fwood/CS532W-539W/homework/6.html\n",
      "10 \"\"\"\n",
      "11 \n",
      "12 import torch\n",
      "13 from torch import tensor\n",
      "14 \n",
      "15 number = (float, int)\n",
      "16 distribution_types = (\n",
      "17     torch.distributions.Normal,\n",
      "18     torch.distributions.Beta,\n",
      "19     torch.distributions.Uniform,\n",
      "20     torch.distributions.Exponential,\n",
      "21     torch.distributions.Categorical,\n",
      "22     torch.distributions.bernoulli.Bernoulli,\n",
      "23     torch.distributions.dirichlet.Dirichlet,\n",
      "24     torch.distributions.gamma.Gamma,\n",
      "25     )\n",
      "26 \n",
      "27 \n",
      "28 def two_arg_op_primitive(op,arg1_arg2):\n",
      "29     arg1, arg2 = arg1_arg2\n",
      "30     return op(arg1, arg2)\n",
      "31 \n",
      "32 \n",
      "33 def add_primitive(arg1_arg2):\n",
      "34     return two_arg_op_primitive(torch.add,arg1_arg2)\n",
      "35 \n",
      "36 \n",
      "37 def subtract_primitive(arg1_arg2):\n",
      "38     return two_arg_op_primitive(torch.subtract,arg1_arg2)\n",
      "39 \n",
      "40 \n",
      "41 def multiply_primitive(arg1_arg2):\n",
      "42     return two_arg_op_primitive(torch.multiply,arg1_arg2)\n",
      "43 \n",
      "44 \n",
      "45 def divide_primitive(arg1_arg2):\n",
      "46     return two_arg_op_primitive(torch.divide,arg1_arg2)\n",
      "47 \n",
      "48 \n",
      "49 def one_arg_op_primitive(op,arg):\n",
      "50     arg0 = arg[0] # because list of len one passed, i.e. [arg0]\n",
      "51     return op(arg0)\n",
      "52 \n",
      "53 \n",
      "54 def sqrt_primitive(arg):\n",
      "55     return one_arg_op_primitive(torch.sqrt,arg)\n",
      "56 \n",
      "57 \n",
      "58 def get_primitive(vector_and_index):\n",
      "59     vector, index = vector_and_index\n",
      "60 \n",
      "61     if isinstance(index,str):\n",
      "62         index_safe = index\n",
      "63     elif torch.is_tensor(index):\n",
      "64         index_safe = index.item()\n",
      "65     else:\n",
      "66         assert False,  'index type {} case not implemented'.format(type(index))\n",
      "67 \n",
      "68     if isinstance(vector,dict):\n",
      "69         return vector[index_safe]\n",
      "70     elif torch.is_tensor(vector):\n",
      "71         assert not isinstance(index,str)\n",
      "72         return vector[index.long()]\n",
      "73     elif isinstance(vector,list):\n",
      "74         index_int = tensor(int(index))\n",
      "75         assert torch.isclose(index_int,index) # TODO: use native pytorch\n",
      "76         return vector[index_int]\n",
      "77     else:\n",
      "78         assert False,  'vector type {} case not implemented'.format(type(vector))\n",
      "79 \n",
      "80 \n",
      "81 def put_primitive(vector_index_overwritevalue):\n",
      "82     vector, index, overwritevalue = vector_index_overwritevalue\n",
      "83 \n",
      "84     if isinstance(index,str):\n",
      "85         index_safe = index\n",
      "86     elif torch.is_tensor(index):\n",
      "87         index_safe = index.item()\n",
      "88     else:\n",
      "89         assert False,  'index type {} case not implemented'.format(type(index))\n",
      "90 \n",
      "91     if isinstance(vector,dict):\n",
      "92         vector[index_safe] = overwritevalue\n",
      "93     elif torch.is_tensor(vector):\n",
      "94         assert not isinstance(index,str)\n",
      "95         vector[index.long()] = overwritevalue\n",
      "96     else:\n",
      "97         assert False,  'vector type {} case not implemented'.format(type(vector))\n",
      "98     return vector\n",
      "99 \n",
      "100 \n",
      "101 def return_idx_primitive(vector,idx_i,idx_f):\n",
      "102     return vector[0][idx_i:idx_f]\n",
      "103 \n",
      "104 \n",
      "105 def first_primitive(vector):\n",
      "106     return return_idx_primitive(vector,idx_i=0,idx_f=1)\n",
      "107 \n",
      "108 \n",
      "109 def second_primitive(vector):\n",
      "110     return return_idx_primitive(vector,idx_i=1,idx_f=2)\n",
      "111 \n",
      "112 \n",
      "113 def last_primitive(vector):\n",
      "114     return return_idx_primitive(vector,idx_i=-1,idx_f=None)\n",
      "115 \n",
      "116 \n",
      "117 def nth_primitive(vector_nth):\n",
      "118     vector, nth = vector_nth\n",
      "119     return return_idx_primitive(vector,idx_i=nth,idx_f=nth+1)\n",
      "120 \n",
      "121 \n",
      "122 def hash_map_primitive(hash_pairs):\n",
      "123     keys = hash_pairs[::2]\n",
      "124     for idx, key in enumerate(keys):\n",
      "125         if torch.is_tensor(key):\n",
      "126             tensor_key = key\n",
      "127             keys[idx] = tensor_key.item()     # dict keys as tensors problematic. can make but lookup fails on fresh but equivalent tensor (bc memory look up?) \n",
      "128         elif isinstance(key,str):\n",
      "129             keys[idx] = key # if ley string, just keep as is\n",
      "130 \n",
      "131     # keys = [tensor_key.item() for tensor_key in keys] \n",
      "132     vals = hash_pairs[1::2]\n",
      "133     return dict(zip(keys, vals))\n",
      "134 \n",
      "135 \n",
      "136 def gt_primitive(consequent_alternative):\n",
      "137     return two_arg_op_primitive(torch.gt,consequent_alternative)\n",
      "138 \n",
      "139 \n",
      "140 def lt_primitive(consequent_alternative):\n",
      "141     return two_arg_op_primitive(torch.lt,consequent_alternative)\n",
      "142 \n",
      "143 \n",
      "144 def ge_primitive(consequent_alternative):\n",
      "145     return two_arg_op_primitive(torch.ge,consequent_alternative)\n",
      "146 \n",
      "147 \n",
      "148 def le_primitive(consequent_alternative):\n",
      "149     return two_arg_op_primitive(torch.le,consequent_alternative)\n",
      "150 \n",
      "151 \n",
      "152 def eq_primitive(consequent_alternative):\n",
      "153     return two_arg_op_primitive(torch.eq,consequent_alternative)\n",
      "154 \n",
      "155 \n",
      "156 def rest_primative(vector):\n",
      "157     return vector[0][1:]\n",
      "158 \n",
      "159 \n",
      "160 def freshvar_primitive(arg):\n",
      "161     return None\n",
      "162 \n",
      "163 \n",
      "164 def vector_primitive(vector):\n",
      "165     ret = list()\n",
      "166     for e in vector:\n",
      "167         try:\n",
      "168             ret.append(e.tolist())\n",
      "169         except:\n",
      "170             ret.append(e)\n",
      "171     try:\n",
      "172         return torch.tensor(ret)\n",
      "173     except:\n",
      "174         return ret\n",
      "175 \n",
      "176             \n",
      "177 def append_primitive(vector_element):\n",
      "178         vector, element = vector_element\n",
      "179         # arg2 must be torch.tensor([float]), not torch.tensor(float) otherwise torch.cat fails\n",
      "180         return torch.cat((vector,torch.Tensor([element])), 0)\n",
      "181 \n",
      "182 \n",
      "183 def tanh_primitive(arg):\n",
      "184     return one_arg_op_primitive(torch.tanh,arg)  \n",
      "185 \n",
      "186 \n",
      "187 def and_primitive(arg1_arg2):\n",
      "188     return two_arg_op_primitive(torch.logical_and,arg1_arg2)  \n",
      "189     \n",
      "190 \n",
      "191 def or_primitive(arg1_arg2):\n",
      "192     return two_arg_op_primitive(torch.logical_or,arg1_arg2)  \n",
      "193 \n",
      "194 \n",
      "195 def abs_primitive(arg):\n",
      "196     return one_arg_op_primitive(torch.abs,arg)\n",
      "197 \n",
      "198 def empty_primitive(args):\n",
      "199     vector = args[0]\n",
      "200     if torch.is_tensor(vector) or isinstance(vector,list):\n",
      "201         return len(vector) == 0\n",
      "202 \n",
      "203     else:\n",
      "204         assert False, 'length for non list or non tensor not implemented'\n",
      "205 \n",
      "206 \n",
      "207 def cons_primitive(args):\n",
      "208     \"\"\"https://bfontaine.net/blog/2014/05/25/how-to-remember-the-difference-between-conj-and-cons-in-clojure/\n",
      "209     \"\"\"\n",
      "210     item, vector = args\n",
      "211     if torch.is_tensor(item) and torch.is_tensor(vector):\n",
      "212         return torch.cat((torch.tensor(item), vector), dim=0)\n",
      "213     elif isinstance(vector,list):\n",
      "214         return [item] + vector\n",
      "215     else:\n",
      "216         assert False, 'not implemented'\n",
      "217 \n",
      "218 def prepend_primitive(args):\n",
      "219     \"\"\"https://bfontaine.net/blog/2014/05/25/how-to-remember-the-difference-between-conj-and-cons-in-clojure/\n",
      "220     \"\"\"\n",
      "221     vector, item  = args\n",
      "222     if torch.is_tensor(item) and torch.is_tensor(vector):\n",
      "223         if item.dim() == 0:\n",
      "224             item = item.reshape(1,)\n",
      "225         elif item.dim() == 1:\n",
      "226             pass\n",
      "227         else:\n",
      "228             assert False, 'not implemented'\n",
      "229         return torch.cat((item,vector), dim=0)\n",
      "230     elif isinstance(vector,list):\n",
      "231         return vector + [item]\n",
      "232     else:\n",
      "233         assert False, 'not implemented'\n",
      "234 \n",
      "235 def conj_primitive(args):\n",
      "236     \"\"\"https://bfontaine.net/blog/2014/05/25/how-to-remember-the-difference-between-conj-and-cons-in-clojure/\n",
      "237     \"\"\"\n",
      "238     vector, item  = args\n",
      "239     if torch.is_tensor(item) and torch.is_tensor(vector):\n",
      "240         assert item.dim() == 0\n",
      "241         return torch.cat((vector,item.reshape(1,)), dim=0)\n",
      "242     elif isinstance(vector,list):\n",
      "243         return vector + [item]\n",
      "244     else:\n",
      "245         assert False, 'not implemented'\n",
      "246 \n",
      "247 \n",
      "248 def log_primitive(arg):\n",
      "249     return one_arg_op_primitive(torch.log,arg) \n",
      "250 \n",
      "251 \n",
      "252 def peek_primitive(vector):\n",
      "253     vector = vector[0]\n",
      "254     # TODO: assert only defined for vectors\n",
      "255     return vector[0]\n",
      "256 \n",
      "257 \n",
      "258 # NB: these functions take a list [c0] or [c0, c1, ..., cn]\n",
      "259 # rely on user to not write something non-sensitcal that will fail (e.g. [\"+\",1,2,3])\n",
      "260 primitives_d = {\n",
      "261     '+': add_primitive,\n",
      "262     '-': subtract_primitive,\n",
      "263     '/': divide_primitive,\n",
      "264     '*': multiply_primitive,\n",
      "265     'sqrt': sqrt_primitive,\n",
      "266     'vector': vector_primitive,\n",
      "267     'get' : get_primitive,\n",
      "268     'put' : put_primitive,\n",
      "269     'first' : first_primitive,\n",
      "270     'second' : second_primitive,\n",
      "271     'last' : last_primitive,\n",
      "272     'nth' : nth_primitive,\n",
      "273     'append' : append_primitive,\n",
      "274     'hash-map' : hash_map_primitive,\n",
      "275     '>':gt_primitive,\n",
      "276     '<':lt_primitive,\n",
      "277     '>=':ge_primitive,\n",
      "278     '<=':le_primitive,\n",
      "279     '=':eq_primitive,\n",
      "280     'rest' : rest_primative,\n",
      "281     'mat-transpose': lambda a: a[0].T,\n",
      "282     'mat-tanh': tanh_primitive,\n",
      "283     'mat-mul': lambda a: torch.matmul(a[0],a[1]),\n",
      "284     'mat-add': add_primitive,\n",
      "285     'mat-repmat': lambda a: a[0].repeat((int(a[1].item()), int(a[2].item()))),\n",
      "286     'and' : and_primitive,\n",
      "287     'or' : or_primitive,\n",
      "288     'abs' : abs_primitive,\n",
      "289     'empty?' : empty_primitive,\n",
      "290     'cons' : cons_primitive,\n",
      "291     'conj' : conj_primitive,\n",
      "292     'log' : log_primitive,\n",
      "293     'peek' : peek_primitive,\n",
      "294     'prepend' : prepend_primitive,\n",
      "295 }\n",
      "296 \n",
      "297 \n",
      "298 def normal(mean_std):\n",
      "299     return two_arg_op_primitive(torch.distributions.Normal,mean_std)\n",
      "300 \n",
      "301 \n",
      "302 def beta(alpha_beta):\n",
      "303     return two_arg_op_primitive(torch.distributions.Beta,alpha_beta)\n",
      "304 \n",
      "305 \n",
      "306 def exponential(lam):\n",
      "307     return one_arg_op_primitive(torch.distributions.Exponential,lam)\n",
      "308 \n",
      "309 \n",
      "310 def uniform(low_hi):\n",
      "311     return two_arg_op_primitive(torch.distributions.Uniform,low_hi)\n",
      "312 \n",
      "313 \n",
      "314 def discrete(prob_vector):\n",
      "315     return one_arg_op_primitive(torch.distributions.Categorical,prob_vector)\n",
      "316 \n",
      "317 \n",
      "318 def flip(prob):\n",
      "319     return one_arg_op_primitive(torch.distributions.bernoulli.Bernoulli,prob)\n",
      "320 \n",
      "321 \n",
      "322 def dirichlet(concentration):\n",
      "323     return one_arg_op_primitive(torch.distributions.dirichlet.Dirichlet,concentration)\n",
      "324 \n",
      "325 \n",
      "326 def gamma(concentration_rate):\n",
      "327     return two_arg_op_primitive(torch.distributions.gamma.Gamma,concentration_rate)\n",
      "328 \n",
      "329 \n",
      "330 distributions_d = {\n",
      "331     'normal': normal,\n",
      "332     'beta': beta,\n",
      "333     'exponential': exponential,\n",
      "334     'uniform-continuous': uniform,\n",
      "335     'discrete': discrete,\n",
      "336     'flip': flip,\n",
      "337     'dirichlet' : dirichlet,\n",
      "338     'gamma' : gamma,\n",
      "339 }\n",
      "340 \n",
      "341 penv = {**distributions_d, **primitives_d}\n"
     ]
    }
   ],
   "source": [
    "import primitives\n",
    "\n",
    "for line_number, function_line in enumerate(getsourcelines(primitives)[0]):\n",
    "    print(line_number, function_line,end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
