{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491b8a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 passed\n",
      "Test 2 passed\n",
      "Test 3 passed\n",
      "Test 4 passed\n",
      "Test 5 passed\n",
      "Test 6 passed\n",
      "Test 7 passed\n",
      "Test 8 passed\n",
      "Test 9 passed\n",
      "Test 10 passed\n",
      "Test 11 passed\n",
      "Test 12 passed\n",
      "Test 13 passed\n",
      "All 13 deterministic tests passed\n",
      "('normal', 5, 1.4142136)\n",
      "p value 0.8007084502688623\n",
      "('beta', 2.0, 5.0)\n",
      "p value 0.570232967759639\n",
      "('exponential', 0.0, 5.0)\n",
      "p value 0.11315320065439927\n",
      "('normal', 5.3, 3.2)\n",
      "p value 0.9547243874435392\n",
      "('normalmix', 0.1, -1, 0.3, 0.9, 1, 0.3)\n",
      "p value 0.7550768772041979\n",
      "('normal', 0, 1.44)\n",
      "p value 0.6280392825189822\n",
      "All probabilistic tests passed\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 1:\n",
      "tensor(3.8318)\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 2:\n",
      "tensor([-11.5714,  -6.0625])\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 3:\n",
      "tensor([2., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 1., 2., 2., 2.])\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 4:\n",
      "[[[-1.7676916122436523], [-1.118196725845337], [-0.9354032278060913], [0.4580332338809967], [1.044437289237976], [-0.4065367579460144], [0.07462392747402191], [-1.051155686378479], [-0.1819164752960205], [-0.801722526550293]], [[2.6741867065429688], [0.512474536895752], [-1.0142426490783691], [0.1489662528038025], [-0.22332051396369934], [0.4326988458633423], [0.24860680103302002], [0.9658144116401672], [-0.41809406876564026], [-0.5750256180763245]], [[0.7798222899436951, -0.42983824014663696, -1.0312782526016235, -0.1406644582748413, -0.8996386528015137, -0.5114136338233948, 0.3236844837665558, -0.855675220489502, 1.986088514328003, 0.45031386613845825], [0.7211995124816895, 0.21626058220863342, 1.1248375177383423, 1.2797229290008545, -1.5293806791305542, 1.6417206525802612, -0.9853824377059937, 1.2712563276290894, 0.0842912346124649, -0.12786734104156494], [-0.057324353605508804, -0.3076135516166687, -0.22628335654735565, 0.308715283870697, 0.9706620573997498, 0.6126998066902161, 1.466538906097412, 0.5463335514068604, -0.6245884299278259, 0.36614343523979187], [2.1768877506256104, 0.5668184161186218, -0.3649443984031677, -0.484836608171463, -0.5604891777038574, -0.1092633306980133, -0.8711755871772766, -0.9893564581871033, -2.622530460357666, -0.19729599356651306], [0.5502117872238159, 0.6832883358001709, 0.521416425704956, 0.9656248092651367, -1.3003575801849365, -0.9540558457374573, -0.17749276757240295, -1.0726393461227417, 0.3236338794231415, -1.5408300161361694], [0.43400198221206665, 2.2279958724975586, 0.6324982643127441, 0.6176543831825256, -0.803342878818512, -0.9014406204223633, -0.4077558219432831, -0.4219468832015991, 0.6329726576805115, 0.4033464789390564], [0.925809919834137, 1.1987119913101196, 0.4856245815753937, 1.4616057872772217, 0.8021788597106934, 0.7660475969314575, 0.42356815934181213, -1.2062325477600098, -1.037696123123169, -0.32846102118492126], [-0.8269684910774231, -0.16437765955924988, 1.0802171230316162, -0.11656741052865982, -1.0195673704147339, -0.6772551536560059, -0.2532135844230652, -0.04122402146458626, -5.8011133660329506e-05, 0.9099297523498535], [-0.6462174654006958, 2.7595667839050293, -0.07100299745798111, 1.001941204071045, -0.37857598066329956, -0.389217346906662, -0.409883975982666, -0.18588533997535706, 1.079423189163208, -0.7631193995475769], [-0.05784069374203682, 1.102362871170044, -1.8171186447143555, -0.1802964061498642, 1.4344890117645264, 0.5055438876152039, 0.7119135856628418, -1.6287842988967896, 0.3141670525074005, 0.12383020669221878]], [[-1.5019057989120483], [0.5333874225616455], [1.367606282234192], [-0.8230386972427368], [0.3667728304862976], [-0.17649102210998535], [-0.9033983945846558], [-0.6441863179206848], [0.3718051016330719], [0.5993713140487671]]]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python evaluation_based_sampling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cc0921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "Test passed\n",
      "All 12 deterministic tests passed\n",
      "('normal', 5, 1.4142136)\n",
      "p value 0.9750933029255907\n",
      "('beta', 2.0, 5.0)\n",
      "p value 0.19567166298785177\n",
      "('exponential', 0.0, 5.0)\n",
      "p value 0.5077823820542168\n",
      "('normal', 5.3, 3.2)\n",
      "p value 0.03229248986313449\n",
      "('normalmix', 0.1, -1, 0.3, 0.9, 1, 0.3)\n",
      "p value 0.22134508762391436\n",
      "('normal', 0, 1.44)\n",
      "p value 0.06801567419824306\n",
      "All probabilistic tests passed\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 1:\n",
      "tensor(-1.9531)\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 2:\n",
      "tensor([ 0.0142, -2.6072])\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 3:\n",
      "tensor([0., 1., 2., 0., 1., 2., 2., 2., 2., 2., 2., 2., 0., 2., 2., 2., 1.])\n",
      "\n",
      "\n",
      "\n",
      "Sample of prior of program 4:\n",
      "[[[0.3404915928840637], [0.07253124564886093], [1.9410412311553955], [1.595449686050415], [0.7876811027526855], [0.7403945922851562], [-0.7994391322135925], [0.1699640154838562], [0.8591791987419128], [-0.43788599967956543]], [[-0.1290707141160965], [0.9287136793136597], [0.13374224305152893], [-0.7232226729393005], [-0.16578589379787445], [0.5664358735084534], [1.3867830038070679], [1.5518771409988403], [-1.3518511056900024], [3.018144130706787]], [[1.2903233766555786, -0.7906650304794312, 0.26601752638816833, 0.7309240698814392, -0.627116858959198, 1.0325922966003418, -1.8757492303848267, -1.059775710105896, -1.3485506772994995, -0.49490001797676086], [-0.9938995838165283, -0.5072317123413086, -0.19611066579818726, 1.3307677507400513, -1.315219521522522, 0.7984453439712524, 0.07256823033094406, -0.5548135638237, -0.007056010887026787, -0.012109244242310524], [0.482983261346817, -0.4422144293785095, -0.7381874918937683, -2.085496187210083, 0.12616091966629028, 0.3482881188392639, 0.867943286895752, 0.5284357666969299, -0.9863168597221375, 0.31645524501800537], [1.0765364170074463, -1.1778278350830078, 0.15887458622455597, -2.273386001586914, 0.49036675691604614, 0.3065895736217499, 1.8558176755905151, 0.14977042376995087, -0.14015142619609833, -1.1439459323883057], [0.8989789485931396, 0.7787042856216431, -0.8660594820976257, -1.717496633529663, 1.5413812398910522, 0.36692044138908386, -0.765255868434906, -1.9025458097457886, 1.4255683422088623, 1.1816129684448242], [1.1142038106918335, -1.6864469051361084, 0.32009685039520264, -0.3467515707015991, -0.8627139925956726, -0.6969993114471436, 0.8607492446899414, 0.6708496809005737, 0.012494700029492378, 0.5289558172225952], [1.3242874145507812, 0.02315308153629303, -1.1985429525375366, -0.5716010928153992, -1.2426120042800903, -1.1988112926483154, 0.8473421931266785, -1.5871920585632324, -1.7627055644989014, 0.0475890152156353], [0.9945656061172485, 1.7476205825805664, -1.2077726125717163, 1.4424941539764404, -0.5761687159538269, 1.848507285118103, 0.6472342014312744, -0.6800799369812012, -0.1219860091805458, -0.6235771179199219], [0.6625446677207947, 1.2416499853134155, 1.3970935344696045, 0.021771788597106934, -0.20723305642604828, -2.1815247535705566, 1.529159426689148, -0.027197113260626793, -1.6421653032302856, 1.9766781330108643], [0.6615936160087585, 1.0952072143554688, -2.07956862449646, -0.33996936678886414, 0.9241219758987427, 0.3169116675853729, 0.6953616142272949, 0.020686496049165726, 1.178383231163025, 1.8796063661575317]], [[-1.6752156019210815], [0.5269629955291748], [-1.063934087753296], [2.432159185409546], [0.39528951048851013], [1.5675228834152222], [0.24734075367450714], [1.1506731510162354], [-0.1022210642695427], [-1.1905789375305176]]]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python graph_based_sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf55424c",
   "metadata": {},
   "source": [
    "# code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "359660d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dill.source import getsource, getsourcelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dacee75",
   "metadata": {},
   "source": [
    "## Algorithm 6 evaluator\n",
    "* I called it `evaluator` and not `eval`, because `eval` is already taken in Python\n",
    "* This recursive function works by evaluating back to a few base cases. These can be seen because they return things directly without calling the `evaluate` recursively\n",
    "  * `return torch.tensor(float(e))` in the case of `(float,int)`\n",
    "  * `return e` in the cases of a `list`, primitive operations `primitives_d`, distributions `distributions_d`, tensor, \n",
    "  \n",
    "  * `return local_env[e]` (ie the bound variable) in the case of a key in the local context `local_env`\n",
    "  * `return distributions_d[cs[0]](cs[1:])` in the case of `cs[0]` being a distribution. ie return the primitive type of distribution\n",
    "  * `return local_env[e`] in the case of something in the local context `local_env`\n",
    "  * `return primitives_d[cs[0]](cs[1:])`, ie do the primitive operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa11004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_based_sampling import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "872abd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 def evaluate(e,local_env={},defn_d={},do_log=False):\n",
      "1     # TODO: get local_env to evaluate values to tensors, not regular floats\n",
      "2     # remember to return evaluate (recursive)\n",
      "3     # everytime we call evaluate, we have to use local_env, otherwise it gets overwritten with the default {}\n",
      "4     if do_log: logger.info('local_env {}'.format(local_env))\n",
      "5     # get first expression out of list or list of one\n",
      "6     if not isinstance(e,list) or len(e) == 1:\n",
      "7         if isinstance(e,list):\n",
      "8             e = e[0]\n",
      "9 \n",
      "10         if isinstance(e, number):\n",
      "11             if do_log: logger.info('match case: number {}'.format(e))\n",
      "12             return torch.tensor(float(e))\n",
      "13         elif isinstance(e,list):\n",
      "14             if do_log: logger.info('match case: list {}'.format(e))\n",
      "15             return e\n",
      "16         elif e in list(primitives_d.keys()):\n",
      "17             if do_log: logger.info('match case: primitives_d {}'.format(e))\n",
      "18             return e\n",
      "19         elif e in list(distributions_d.keys()):\n",
      "20             if do_log: logger.info('match case: distributions_d {}'.format(e))\n",
      "21             return e\n",
      "22         elif torch.is_tensor(e) and not len(list(e.shape)) == 0:\n",
      "23             if do_log: logger.info('match case: is_tensor {}'.format(e))\n",
      "24             return e\n",
      "25         elif e in local_env.keys():\n",
      "26             if do_log: logger.info('match case: local_env, e {}'.format(e))\n",
      "27             if do_log: logger.info('match case: local_env, local_env[e] {}'.format(local_env[e]))\n",
      "28             return local_env[e] # TODO return evaluate?\n",
      "29         elif e in list(defn_d.keys()):\n",
      "30             if do_log: logger.info('match case: defn_d {}'.format(e))\n",
      "31             return e\n",
      "32         elif isinstance(e,distribution_types):\n",
      "33             if do_log: logger.info('match case: distribution {}'.format(e))\n",
      "34             return e\n",
      "35         else:\n",
      "36             assert False\n",
      "37     elif e[0] == 'sample':\n",
      "38         if do_log: logger.info('match case: sample {}'.format(e))\n",
      "39         distribution = evaluate(e[1],local_env,defn_d,do_log=do_log)\n",
      "40         return distribution.sample() # match shape in number base case\n",
      "41     elif e[0] == 'observe':\n",
      "42         return None\n",
      "43     elif e[0] == 'let': \n",
      "44         if do_log: logger.info('match case: let {}'.format(e))\n",
      "45         # let [v1 e1] e0\n",
      "46         # here \n",
      "47             # e[0] : \"let\"\n",
      "48             # e[1] : [v1, e1]\n",
      "49             # e[2] : e0\n",
      "50         # evaluates e1 to c1 and binds this value to e0\n",
      "51         # this means we update the context with old context plus {v1:c1}\n",
      "52         c1 = evaluate(e[1][1],local_env,defn_d,do_log=do_log) # evaluates e1 to c1\n",
      "53         v1 = e[1][0]\n",
      "54         return evaluate(e[2], local_env = {**local_env,v1:c1},defn_d=defn_d,do_log=do_log)\n",
      "55     elif e[0] == 'if': # if e0 e1 e2\n",
      "56         if do_log: logger.info('match case: if {}'.format(e))\n",
      "57         e0 = e[1]\n",
      "58         e1 = e[2]\n",
      "59         e2 = e[3]\n",
      "60         if evaluate(e0,local_env,defn_d,do_log=do_log):\n",
      "61             return evaluate(e1,local_env,defn_d,do_log=do_log)\n",
      "62         else:\n",
      "63             return evaluate(e2,local_env,defn_d,do_log=do_log) \n",
      "64 \n",
      "65     else:\n",
      "66         cs = []\n",
      "67         for ei in e:\n",
      "68             if do_log: logger.info('cycling through expressions. ei {}'.format(ei))\n",
      "69             c = evaluate(ei,local_env,defn_d,do_log=do_log)\n",
      "70             cs.append(c)\n",
      "71         if cs[0] in primitives_d:\n",
      "72             if do_log: logger.info('do case primitives_d: cs0 {}'.format(cs[0]))\n",
      "73             if do_log: logger.info('do case primitives_d: cs1 {}'.format(cs[1:]))\n",
      "74             if do_log: logger.info('do case primitives_d: primitives_d[cs[0]] {}'.format(primitives_d[cs[0]]))\n",
      "75             return primitives_d[cs[0]](cs[1:])\n",
      "76         elif cs[0] in distributions_d:\n",
      "77             if do_log: logger.info('do case distributions_d: cs0 {}'.format(cs[0]))\n",
      "78             return distributions_d[cs[0]](cs[1:])\n",
      "79         elif cs[0] in defn_d:\n",
      "80             if do_log: logger.info('do case defn: cs0  {}'.format(cs[0]))\n",
      "81             defn_function_li = defn_d[cs[0]]\n",
      "82             defn_function_args, defn_function_body = defn_function_li\n",
      "83             local_env_update = {key:value for key,value in zip(defn_function_args, cs[1:])}\n",
      "84             if do_log: logger.info('do case defn: update to local_env from defn_d {}'.format(local_env_update))\n",
      "85             return evaluate(defn_function_body,local_env = {**local_env, **local_env_update},defn_d=defn_d,do_log=do_log)\n",
      "86         else:\n",
      "87             assert False\n"
     ]
    }
   ],
   "source": [
    "for line_number, function_line in enumerate(getsourcelines(evaluate)[0]):\n",
    "    print(line_number, function_line,end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bfcf9b",
   "metadata": {},
   "source": [
    "For the primitives and distributions, I made the design choice that they would take in a parsed `list`, `cs[1:]`. I used the name of the input list of the function as documentation of what is expected, e.g. `normal(mean_std)`. I also modularized some parsing in `one_arg_op_primitive` and `two_arg_op_primitive`, and used these as internal helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c161d51",
   "metadata": {},
   "source": [
    "One challenge I encountered at the very end of the assignment was generalizing my `vector` primitive to work properly to construct multidimensional arrays. I was getting shape mismatch errors in the Neural Network example `4.daphne`, and try as I might, I couldn't write a `vector` primitive that could properly get all the different cases working. Sometimes `vector` yielded a list of distributions. Sometimes a `torch.tensor([float_1,...,float_n])` of shape `(n,)`, or a tensor of what `(n,1)` other way: `torch.tensor([[float_1],...,[float_n]])`. It got to the point where I had a vector primitive that was dozens of cases, and very hacky, and uninterpretable. The root cause of all this pain was that I had made the design choice early on to return `torch.tensor.([float])` instead of `torch.tensor.(float)`. Big mistake. As soon as I changed this, I could write a much simpler `vector` primitive to break into a few cases of returning a `list` (e.g. of distributions), `torch.tensor` and `torch.stack`, and things came together.\n",
    "\n",
    "I had originally made this choice to get `append` working with `torch.cat`, because its second argument needs to be `torch.tensor.([float])` not `torch.tensor.(float)`. So I just needed to include the append `primitive` to include this case by reworking the second argument.\n",
    "\n",
    "I trouble shooted by running `evaluate(parsed_4_daphne,do_log=True)` and looking at the local context, noting shapes, and seeing what was causing things to fail. The evaluation based sampling is interpretable step by step, and the shapes of what things should be was seen from the code (e.g. vector of 1x1 vectors, so column vector instead of row vector). Lesson: read ahead a bit to how primitives are used, because making design choices that get burned into the code base.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d9b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ :\n",
      "0 def add_primitive(arg1_arg2):\n",
      "1     return two_arg_op_primitive(torch.add,arg1_arg2)\n",
      "\n",
      "- :\n",
      "0 def subtract_primitive(arg1_arg2):\n",
      "1     return two_arg_op_primitive(torch.subtract,arg1_arg2)\n",
      "\n",
      "/ :\n",
      "0 def divide_primitive(arg1_arg2):\n",
      "1     return two_arg_op_primitive(torch.divide,arg1_arg2)\n",
      "\n",
      "* :\n",
      "0 def multiply_primitive(arg1_arg2):\n",
      "1     return two_arg_op_primitive(torch.multiply,arg1_arg2)\n",
      "\n",
      "sqrt :\n",
      "0 def sqrt_primitive(arg):\n",
      "1     return one_arg_op_primitive(torch.sqrt,arg)\n",
      "\n",
      "vector :\n",
      "0 def vector_primitive(vector):\n",
      "1     ret = list()\n",
      "2     for e in vector:\n",
      "3         try:\n",
      "4             ret.append(e.tolist())\n",
      "5         except:\n",
      "6             ret.append(e)\n",
      "7     try:\n",
      "8         return torch.FloatTensor(ret)\n",
      "9     except:\n",
      "10         return ret\n",
      "\n",
      "get :\n",
      "0 def get_primitive(vector_and_index):\n",
      "1     vector, index = vector_and_index\n",
      "2     if isinstance(vector,dict):\n",
      "3         return vector[index.item()]\n",
      "4     elif torch.is_tensor(vector):\n",
      "5         return vector[index.long()]\n",
      "6     elif isinstance(vector,list):\n",
      "7         index_int = int(index)\n",
      "8         assert np.isclose(index_int,index) # TODO: use native pytorch\n",
      "9         return vector[index_int]\n",
      "10     else:\n",
      "11         assert False,  'vector type {} case not implemented'.format(type(vector))\n",
      "\n",
      "put :\n",
      "0 def put_primitive(vector_index_overwritevalue):\n",
      "1     vector, index, overwritevalue = vector_index_overwritevalue\n",
      "2     if isinstance(vector,dict):\n",
      "3         vector[index.item()] = overwritevalue\n",
      "4     elif torch.is_tensor(vector):\n",
      "5         vector[index.long()] = overwritevalue\n",
      "6     else:\n",
      "7         assert False,  'vector type {} case not implemented'.format(type(vector))\n",
      "8     return vector\n",
      "\n",
      "first :\n",
      "0 def first_primitive(vector):\n",
      "1     return return_idx_primitive(vector,idx_i=0,idx_f=1)\n",
      "\n",
      "second :\n",
      "0 def second_primitive(vector):\n",
      "1     return return_idx_primitive(vector,idx_i=1,idx_f=2)\n",
      "\n",
      "last :\n",
      "0 def last_primitive(vector):\n",
      "1     return return_idx_primitive(vector,idx_i=-1,idx_f=None)\n",
      "\n",
      "nth :\n",
      "0 def nth_primitive(vector_nth):\n",
      "1     vector, nth = vector_nth\n",
      "2     return return_idx_primitive(vector,idx_i=nth,idx_f=nth+1)\n",
      "\n",
      "append :\n",
      "0 def append_primitive(vector_element):\n",
      "1         vector, element = vector_element\n",
      "2         # arg2 must be torch.tensor([float]), not torch.tensor(float) otherwise torch.cat fails\n",
      "3         return torch.cat((vector,torch.Tensor([element])), 0)\n",
      "\n",
      "hash-map :\n",
      "0 def hash_map_primitive(hash_pairs):\n",
      "1     keys = hash_pairs[::2]\n",
      "2     # dict keys as tensors problematic. can make but lookup fails on fresh but equivalent tensor (bc memory look up?) \n",
      "3     keys = [tensor_key.item() for tensor_key in keys] \n",
      "4     vals = hash_pairs[1::2]\n",
      "5     return dict(zip(keys, vals))\n",
      "\n",
      "> :\n",
      "0 def gt_primitive(consequent_alternative):\n",
      "1     return two_arg_op_primitive(torch.gt,consequent_alternative)\n",
      "\n",
      "< :\n",
      "0 def lt_primitive(consequent_alternative):\n",
      "1     return two_arg_op_primitive(torch.lt,consequent_alternative)\n",
      "\n",
      ">= :\n",
      "0 def ge_primitive(consequent_alternative):\n",
      "1     return two_arg_op_primitive(torch.ge,consequent_alternative)\n",
      "\n",
      "<= :\n",
      "0 def le_primitive(consequent_alternative):\n",
      "1     return two_arg_op_primitive(torch.le,consequent_alternative)\n",
      "\n",
      "== :\n",
      "0 def eq_primitive(consequent_alternative):\n",
      "1     return two_arg_op_primitive(torch.eq,consequent_alternative)\n",
      "\n",
      "rest :\n",
      "0 def rest_primative(vector):\n",
      "1     return vector[0][1:]\n",
      "\n",
      "mat-transpose :\n",
      "0     'mat-transpose': lambda a: a[0].T,\n",
      "\n",
      "mat-tanh :\n",
      "0 def tanh_primitive(arg):\n",
      "1     return one_arg_op_primitive(torch.tanh,arg)  \n",
      "\n",
      "mat-mul :\n",
      "0     'mat-mul': lambda a: torch.matmul(a[0],a[1]),\n",
      "\n",
      "mat-add :\n",
      "0 def add_primitive(arg1_arg2):\n",
      "1     return two_arg_op_primitive(torch.add,arg1_arg2)\n",
      "\n",
      "mat-repmat :\n",
      "0     'mat-repmat': lambda a: a[0].repeat((int(a[1].item()), int(a[2].item()))),\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from primitives import primitives_d\n",
    "for key in primitives_d.keys() :\n",
    "    print(key,':')\n",
    "    for line_number, function_line in enumerate(getsourcelines(primitives_d[key])[0]):\n",
    "        print(line_number, function_line,end='')\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from primitives import distributions_d\n",
    "\n",
    "for key in distributions_d.keys() :\n",
    "    print(key,':')\n",
    "    for line_number, function_line in enumerate(getsourcelines(distributions_d[key])[0]):\n",
    "        print(line_number, function_line,end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41345a",
   "metadata": {},
   "source": [
    "## defn\n",
    "I implemented the defn in `evaluate_program`, which is a layer above the recursive `evaluate`, beause the programs had the functional definitions at the beginning of the program. I simply parsed this in `evaluate_program`, and made a binding of the defn function name string to the args and expression body : `defn_d[defn_function_name] = [defn_function_args,defn_function_body]`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e920f935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 def evaluate_program(ast,sig=None,do_log=False):\n",
      "1     \"\"\"Evaluate a program as desugared by daphne, generate a sample from the prior\n",
      "2     Args:\n",
      "3         ast: json FOPPL program\n",
      "4     Returns: sample from the prior of ast\n",
      "5     \"\"\"\n",
      "6     defn_d ={}\n",
      "7     ast0 = ast[0]\n",
      "8     \n",
      "9     if ast0[0] == 'defn':\n",
      "10         defn_function_name = ast0[1]\n",
      "11         defn_function_args = ast0[2]\n",
      "12         defn_function_body = ast0[3]\n",
      "13         defn_d[defn_function_name] = [defn_function_args,defn_function_body]\n",
      "14         ast1 = ast[1]\n",
      "15         res = evaluate(ast1,defn_d=defn_d,do_log=do_log)\n",
      "16     elif len(ast) == 1:\n",
      "17         res = evaluate(ast0,defn_d=defn_d,do_log=do_log)\n",
      "18     else:\n",
      "19         assert False\n",
      "20     return res, sig\n"
     ]
    }
   ],
   "source": [
    "from evaluation_based_sampling import evaluate_program\n",
    "for line_number, function_line in enumerate(getsourcelines(evaluate_program)[0]):\n",
    "    print(line_number, function_line,end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91f4b6",
   "metadata": {},
   "source": [
    "The `evaluate` function handles `denf`s by updating the local context dictionary to bind the args to the evaluation of the args (eventually reduces to constants) that were passed to it when it was called. The return is the evaluation of the function body, under the updated local context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84dc70b",
   "metadata": {},
   "source": [
    "There are some logger functionality to help debugging, and also `assert False` to catch unforseen cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973c544",
   "metadata": {},
   "source": [
    "I added in some functinoality to write the daphne parsed abstract syntax trees and graphs to jsons, and check if they exist. This avoids re-doing parsing redundantly, and speeds up the development cycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8ffc9",
   "metadata": {},
   "source": [
    "# `graph_based_sampling`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0ea64",
   "metadata": {},
   "source": [
    "The `deterministic_eval` in `graph_based_sampling` is using the exact same `evaluate` helper function as in `evalute_based_sampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_based_sampling import deterministic_eval\n",
    "print(getsource(deterministic_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d79706",
   "metadata": {},
   "source": [
    "The ancestral sampling is done with `sample_from_joint`, which parses the daphne output json graph structure, and then traverses the graph, calling the `evaluate` internally on the expressions.\n",
    "\n",
    "The ancestral part is ensured by \n",
    "  * performing a topological sort on the verteces\n",
    "    * using the information of the arcs to construct a graph, and then using a topological sort routine I found online, and slighlt massaged to work in this case.\n",
    "  * walking thorugh each top sorted vertex (the ancestral part in ancestral sampling)\n",
    "  * evaluating the expressions as they arise into a distribution\n",
    "  * taking a sample (the sampling part in ancestral sampling), which evaluates to a constant\n",
    "  * updating the local context of the evaluator with this sampling variable name bound to its sampled constant value, and \n",
    "  * passing by observes and doing nothing\n",
    "  * At the end of the graph traversal, the local context bindings we have accumulated have all the information we need for the evaluaton of the expression in the return / meaning of the program. We simply call `evaluate` one more time with these bindings used in the local context (they only have sample variables in them).\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
